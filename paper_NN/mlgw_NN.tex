\documentclass[twocolumn,showpacs,preprintnumbers,nofootinbib,prd,
superscriptaddress,10pt]{revtex4-1}

\usepackage{amsmath,amssymb}
\usepackage{amsfonts}
\usepackage[normalem]{ulem}
\usepackage{textcomp}
\usepackage{hyperref}
\usepackage{enumitem}
\usepackage{bm}
\usepackage{afterpage}
\usepackage{graphicx}
\usepackage{psfrag}
\usepackage{mathtools}
\usepackage{tensor}
\usepackage{layouts}
\usepackage{DejaVuSans}
\usepackage{epstopdf}
\usepackage[usenames,dvipsnames]{xcolor}
\usepackage[utf8]{inputenc}
\usepackage{multirow}
\usepackage{rotating}
\usepackage{tabularx}
\usepackage{ragged2e}
\usepackage{blindtext}
\usepackage{graphicx}
\usepackage{siunitx}
	\sisetup{output-decimal-marker={.}}
	
	%some math symbols
\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
\DeclareMathOperator{\sign}{sign}
\renewcommand{\d}[1]{\ensuremath{\operatorname{d}\!{#1}}}
%argmin and argmax
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

% comments command
\newcommand{\stefano}[1]{{\textcolor{red}{\texttt{S: #1}} }}
\newcommand{\tim}[1]{{\textcolor{green}{\texttt{T: #1}} }}
\newcommand{\chinmay}[1]{{\textcolor{blue}{\texttt{C: #1}} }}
\newcommand{\oldnewtxt}[2]{\sout{#1}\textcolor{red}{#2}}

\begin{document}

	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% ABSTRACT
\begin{abstract}

WRITEME

\end{abstract}
	
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% TITLE
	\title{mlgw NN}
	\author{Tim \surname{Grimbergen}}
        \affiliation{Institute for Gravitational and Subatomic Physics (GRASP),
		Utrecht University, Princetonplein 1, 3584 CC Utrecht, The Netherlands}
	%
	\author{Stefano \surname{Schmidt}}
		\email{s.schmidt@uu.nl}
        \affiliation{Institute for Gravitational and Subatomic Physics (GRASP),
		Utrecht University, Princetonplein 1, 3584 CC Utrecht, The Netherlands}
        \affiliation{Nikhef, Science Park 105, 1098 XG, Amsterdam, The Netherlands}
	%
	\author{Chinmay \surname{Kalaghatgi}}
        \affiliation{Institute for Gravitational and Subatomic Physics (GRASP),
		Utrecht University, Princetonplein 1, 3584 CC Utrecht, The Netherlands}
        \affiliation{Nikhef, Science Park 105, 1098 XG, Amsterdam, The Netherlands}
	%
	\author{Chris \surname{van den Broeck}}
        \affiliation{Institute for Gravitational and Subatomic Physics (GRASP),
		Utrecht University, Princetonplein 1, 3584 CC Utrecht, The Netherlands}
        \affiliation{Nikhef, Science Park 105, 1098 XG, Amsterdam, The Netherlands}
	\maketitle

	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% BODY  
\section{Introduction}
\label{sec:intro}
\blindtext \cite{Schmidt:2020yuu}

%%%%%%%%%%%%%%%%%%%
\section{Building the model}
\label{sec:model}

A non-precessing BBH can be described by four {\it intrisic} parameters, which specify the two BH masses $m_1$ and $m_2$ and the z-component of the two spin $s_1$ and $s_2$.
Moreover, since the total mass $M = m_1 + m_2$ sets an overall amplitude scaling, the non-precessing BBH signal only depends on the mass ratio $q = m_1/m2 \geq 1$ as well as on the spins. We may refers to these parameter as $\boldsymbol{\vartheta} = (q, s_1, s_2)$.
Besides the masses and spins, the gravitational wave emitted by the system depends also on luminosity distance to the source $d_L$, the inclination angle $\iota$ of the source and the reference phase $\varphi_0$: we call them {\it extrinsic}.

As it is standard, we expand the angular dependence on $\iota, \varphi_0$ of the {\it complex} waveform $h(t)$ in terms of a sum of spin -2 spherical harmonics, leading to the following expression for the waveform:
A GW is then parametrized\footnote{Such parametrization is particularly convenient as it separates the waveform dependence over intrinsic and extrisinc parameters.} as~\cite{Estelles:2021gvs}:
\begin{align} \label{eq:h_parametrization}
	&h(t; d_L,\iota,\varphi_0, m_1, m_2, s_1, s_2) = h_+ + i h_\times \nonumber \\
		&\qquad= \frac{G}{c^2} \frac{M}{d_L}\sum_{\ell = 2}^{\infty} \sum_{m = -\ell}^{\ell} \tensor[^{-2}]{Y}{_{\ell m}}(\iota, \varphi_0) h_{\ell m}(t/M; \boldsymbol{\vartheta})
\end{align}
where we refer to the functions $h_{\ell m}(t; \boldsymbol{\vartheta})$ as {\it modes} of the waveform. We note that that, for non-precessing systems, $h_{\ell m} = (-1)^\ell h^*_{\ell -m}$.

In this work we introduce a Machine Learning model to perform a regression
\begin{align}\label{eq:objective}
	(q, s_1, s_2) &\longmapsto h_{\ell m}(t; \boldsymbol{\vartheta})
\end{align}
for each mode $(\ell,m)$.
The regression is designed to reproduce waveforms from a given dataset; such waveforms can be generated by {\it any} time-domain approximant.

We decompose each mode in amplitude and phase
\begin{equation}
	h_{\ell m}(t; \boldsymbol{\vartheta}) = A_{\ell m}(t; \boldsymbol{\vartheta}) e^{i \phi_{\ell m}(t; \boldsymbol{\vartheta})}
\end{equation}
and, for each mode, we perform a regression for amplitude and phase separately. The regression scheme closely follows \cite{Schmidt:2020yuu} and relies on:
\begin{enumerate}[label=(\alph*)]
	\item a suitable vector representation of the regression target by choosing a fixed time grid
	\item a Principal Component Analysis (PCA) model to reduce the dimensionality of each waveform
	\item a Neural Network (NN) regression to learn the dependence on $\boldsymbol{\vartheta}$ of the reduced waveform
\end{enumerate}

While the first two elements are unchanged from the previous work, the NN regression is first introduced here. Indeed a NN has more representation power than the Mixture of Experts (MoE) model \cite{Jacobs1991AdaptiveMoE}, used in \cite{Schmidt:2020yuu}: the change was needed to achieve better accuracy for the model.

\subsection{Dataset creation}
\label{sec:dataset}

To construct a dataset, we follow \cite{Schmidt:2020yuu} and we set a dimensionless time grid. We construct the grid by setting $D$ points equally spaced in $\tau^\alpha$, where $\tau = t/M$. Using the findings of \cite{Schmidt:2020yuu}, we set $D = \text{???}$ and $\alpha = \text{???}$.
%
This is a good compromise between the need of having a faithful representation of the waveform (which requires a large grid) and the need of having a compact model (which points to a sparse grid).

The starting point of the grid $\tau_0$ sets the length of the waveform that our model is able to generate. We choose $\tau_0 = \text{???}$.

Once a time grid is set, we evaluate all the modes (amplitude and phase) on the time grid and represent them as vectors in $\R^D$.
We then create a dataset $\{X, Y\}$ of $N$ elements. Each row of the dataset is of the form:
\begin{align}
	X &= [q, s_1, s_2] \\
	Y &= [\boldsymbol{A}^T_{\ell m}, \boldsymbol{\phi}^T_{\ell m}, \hdots ] 
\end{align}
%
The dataset $Y$ gathers the amplitude and phase for the different $L$ modes in the dataset.
In what follows we will refer to any of the vectors $\boldsymbol{A}_{\ell m}$ or $\boldsymbol{\phi}_{\ell m}$ as $\boldsymbol{f}$.
Note that we use the same grid for all the modes.

\subsection{Dimensionality reduction}
\label{sec:PCA}

It is unfeasibile to perform a regression targeting a large dimensional vector such as $\boldsymbol{f} \in \R^D$. For this reason, in \cite{Schmidt:2020yuu} we introduced a Principal Component Analysis (PCA) dimensionality reduction scheme.
It is an approximately invertible linear mapping between a vector $\boldsymbol{f} \in \R^D$ in a large dimensional space to lower dimensional vector  $\boldsymbol{g} \in \R^K$:
%
\begin{align}
	\mathbf{g} = H (\mathbf{f} - \boldsymbol{\mu}) \label{eq:PCA_reduction_model}\\
	\mathbf{f} = H^T \mathbf{g} + \boldsymbol{\mu} \label{eq:PCA_reconstruction_model}
\end{align}
where $\boldsymbol{\mu} \in \R^D$ and $H$ is a $K \times D$ matrix. Their value is set by looking at the dataset, as described in \cite[Sec. 12]{murphy2012machine}.


\subsection{Neural network regression}
\label{sec:NN}

A neural network is a function

%%%%%%%%%%%%%%%%%%%
\section{Performance study}
\label{sec:performance}
\blindtext
\subsection{Hyperparameter optimization}
\label{sec:hyperparameter}

\subsection{Accuracy study}
\label{sec:accuracy}
\begin{itemize}
	\item mode by mode
	\item overall
\end{itemize}

\subsection{Parameter Estimation}
\label{sec:PE}
gw150914? Or other events?

\subsection{Timing study}
\label{sec:timing}

%%%%%%%%%%%%%%%%%%%

\section{Final remarks and future prospects}
\label{sec:end}
\blindtext


	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% END & BIB


        \begin{acknowledgments}
          %
          This research has made use of data, software and/or web tools obtained 
          from the Gravitational Wave Open Science Center (https://www.gw-openscience.org), 
          a service of LIGO Laboratory, the LIGO Scientific Collaboration and the 
          Virgo Collaboration. LIGO is funded by the U.S. National Science Foundation. 
          Virgo is funded by the French Centre National de Recherche Scientifique (CNRS), 
          the Italian Istituto Nazionale della Fisica Nucleare (INFN) and the 
          Dutch Nikhef, with contributions by Polish and Hungarian institutes.
        \end{acknowledgments}

	\bibliography{biblio.bib}
	\bibliographystyle{ieeetr}

\end{document}



