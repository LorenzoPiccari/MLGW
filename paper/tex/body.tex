\section{Introduction}
The detection of Gravitational Waves (GW) from compact binary coalescences (CBC) has been possible thanks to the joint effort of a number of different fields of expertise, all joining together to achieve the sophisticated detection process. GW data analysis concerns the detection of a GW signal hidden in the raw detector output (\textit{matched filtering}) and subsequently the inference of its physical properties (\textit{parameter estimation}). In order to accomplish its goal, GW data analysis relies on the availability of waveform (WF) templates to compare with the detector output.
To accurately explore the posterior distribution for the parameters defining a CBC, state-of-the-art parameter estimation (PE) algorithms~\cite{Aasi:2013jjl}~\cite{Veitch2014wba} can require the generation of as many as $10^7$ waveform templates. It is therefore paramount for the waveform generation to be as fast as possible. At the same time, because of the extreme sensitivity to phase differences in the likelihood  function, the templates must retain a high degree of accuracy to avoid biases in the posterior exploration.
\par
Many efforts have been devoted to solve Einstein equations for two coalescing objects and to predict the gravitational radiation emitted~\cite{}.
As solving the full equations is still extremely computationally challenging, the LIGO-Virgo Collaboration relies on approximate analytical models. These can be broadly categorised in  two families; (i) the effective-one-body(EOB) waveform models~\cite{Damour1999EOB}~\cite{Damour2009EOB}; (ii) the phenomenological models~\cite{}. 
EOB models are the most accurate family of analytical models available. They compute the GW signal by solving Hamilton's equations and accurately predict the GW signal up to the plunge. The merger and ringdown  parts 
of the signal are then joint to the inspiral signal using information obtained from numerical relativity. Because of the numerical integrations involved, they tend to be accurate, but slow to generate, see however \cite{} for a much faster approach \textbf{(Is this about ROMs?? Or other??)}. The phenomenological waveform are based on the post-Newtonian formalism and then calibrated on EOB waveforms and numerical relativity. They tend to be much faster than EOB models, but not as accurate.
Many efforts have been devoted to the task of speeding up the generation of GW signals from EOB families.
They have come to be known as \textit{surrogate models}. Surrogate modelse are constructed 
starting from some decomposition in the waveform space followed by efficient interpolation to avoid any  numerical integration. Being fast to generate, they are routinely employed in GW data analysis. 
\par
A Machine Learning model is a promising alternative to the state-of-the-art waveforms generators. Machine Learning (ML) is a branch of statistics that is devoted to reproduce patterns read from data. A ML algorithm needs very little human input and, by a automatically solving an optimization problem, it is able to choose the best performing element among a large class of parametric models for the solution. This is the so-called training procedure. The ML flexibility in modelling data and reproducing trends is appealing: with a proper model choice and with an appropriate training procedure, we can hope to have a reliable, fast to execute generator of GW waveforms, while retaining the accuracy necessary for robust parameter estimation.
\par
In this work, we explore this opportunity. We developed a ML model that is able to generate a GW signal from a binary black hole (BBH) coalescence.
We train our model with WFs generated by \texttt{TEOBResumS} \cite{Nagar2018TEOBResumS} model and we demonstrate that it can generate GW signals significantly faster than EOB models, matching the performances of a Reduced Order Modelling (ROM)~\cite{Purrer_2014_ROM}~\cite{Purrer_2016_FDROM}~\cite{Boh2017SEOBNRv4}. At the same time it keeps the same accuracy of the underlying training model. Moreover, we present a successful application in a parameter estimation setting, by computing posterior distributions for GW150914.
\par
Our model can be effectively applied to several open problems in GW data analysis.
First of all, being among the fastest Inspiral-Merger-Ringdown waveform models and matching the state-of-the-art accuracy, it could be used to speed up the search of GW waves and the subsequent analysis.
Furthermore, it is crucial to realise that with our model, the time required to generate a WF does not depend on the lenght of the signal but only on the number of grid points which the WF is evaluated at. Such feature will be crucial for future surveys (e.g. LISA, ET), where "long" signals are expected to be detected, and the problem of the fast generation of a WF will be more pressing.
\par
Finally, our model can be employed for a systematic analysis of the detected signals so far. Being fast to run, it would perform accurate parameter estimation in a low amount of time and it could allow for a comparison between different surrogate WF models\footnote{Indeed it could be trained with different surrogate models: this would create a fast version of the underlying EOB model, which could be employed for parameter estimation.}
, thus yielding invaluable information about the relevant physics.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Problem specification}
We now provide a precise statement of the objective of our work.
A binary black hole is parametrized by a vector $ \boldsymbol{\vartheta} = (m_1,m_2, \mathbf{s}_1,\mathbf{s}_2) $, where $m_i$ are the BHs masses and $\mathbf{s}_i = \frac{\mathbf{S}_i}{m_i^2} <1$ are the \textit{dimensionless} spin. 
We call them the \textit{orbital parameters}.
Let the wave direction of propagation be identified with the spherical coordinates $(d_L, \iota, \varphi_0)$, where $d_L$ is the luminosity distance, $\iota$ the polar angle and $\varphi_0$ the azimuthal angle. The polar angle $\iota$ is also called inclination and it is measured with respect to the normal to the orbital plane.
A GW is parametrized as \cite{ajith2007dataformatsNRWF}:
\begin{align} \label{eq:h_parametrization}
	&h(t, d_L,\iota,\varphi_0; \boldsymbol{\vartheta}) = h_+ + i h_\times \nonumber \\
		&\qquad= {\frac{\SI{1}{Mpc}}{d_L}} \sum_{m = -2}^{2} \tensor[^{-2}]{Y}{_{2 m}}(\iota, \varphi_0) \cdot H_{2m}(t; \boldsymbol{\vartheta})
\end{align}
where $\tensor[^{-2}]{Y}{_{l m}}(\iota, \varphi_0)$ are the spin-2 spherical harmonics.
In the expression, and for the rest of this paper, we included only the lowest order term in the multipole expansion, which is the dominant term in every realistic case.
We call $(m_1,m_2, \mathbf{s}_1,\mathbf{s}_2, d_L,\iota,\varphi_0)$ \textit{physical parameters} and they fully express the source proprieties as well as its orientation and position.
In what follows, we will concentrate on the case in which spins $\mathbf{s}_1$ and $\mathbf{s}_2$ are \textit{aligned}. We plan to extend the experience acquired with this simplified problem to the vastly more complicated case of generic and thus precessing spins.
\par
In the case of aligned spins, Eq.~\eqref{eq:h_parametrization} can be further simplified.
It turns out that $|H_{2\pm 2}| >> |H_{2\pm 1}|,|H_{20}|$ and this means that the $|m| \neq 2$ modes of the multipole expansion can be safely neglected.
Furthermore, because of parity invariance, it holds $H_{22} = H_{2 -2}^*$.
Thus a waveform can be fully expressed by the single complex quantity $H_{22}$. We define:
\begin{equation}\label{eq:h_std}
	\tilde{h}(t; \boldsymbol{\vartheta}) \equiv \tensor[^{-2}]{Y}{_{2 2}}(0,0) \cdot H_{22}(t; \boldsymbol{\vartheta}) = 4\cdot\sqrt{\frac{5}{64\pi}}H_{22}(t; \boldsymbol{\vartheta})
\end{equation}
With this definition, the full waveform can be expressed as:
\begin{align} 
	&h(t, d_L,\iota,\varphi_0; \boldsymbol{\vartheta}) =  \nonumber\\
		%&= {\frac{\SI{1}{Mpc}}{d_L}} \left[ \tensor[^{-2}]{Y}{_{2 2}}(\iota, \varphi_0) \cdot H_{22}(t; \boldsymbol{\vartheta}) + \tensor[^{-2}]{Y}{_{2 -2}}(\iota, \varphi_0) \cdot H_{22}^*(t; \boldsymbol{\vartheta}) \right] \nonumber\\
		&= {\frac{\SI{1}{Mpc}}{d_L}} \cdot \Bigg\{ \frac{1+\cos^2\iota}{2} \left[ \cos 2\varphi_0 \cdot \mathrm{Re}(\tilde{h}) 
			- \sin 2\varphi_0 \cdot \mathrm{Im}(\tilde{h}) \right] \nonumber \\
		&+  i \cdot \cos\iota \left[ \sin 2\varphi_0 \cdot \mathrm{Re}(\tilde{h}) 
			+ \cos 2\varphi_0 \cdot \mathrm{Im}(\tilde{h})  \right] \Bigg\}
\label{eq:h_parametrization_simple}
\end{align}
where we split the real and the imaginary part of $h$ and we used the relation ${\tensor[^{-2}]{Y}{_{2 \pm 2}}(\iota, \varphi_0) = (1 \pm \cos \iota)^2 e^{\pm i 2 \varphi_0}}$.
\par
We express $H_{22}$ in terms of two functions $A(t; \boldsymbol{\vartheta})$ and $\phi(t; \boldsymbol{\vartheta})$ such that:
\begin{equation}\label{eq:h_ML}
	\tilde{h}(t; \boldsymbol{\vartheta}) = A(t; \boldsymbol{\vartheta}) e^{i \phi(t; \boldsymbol{\vartheta})} 
\end{equation}
%%%
We may also write $f_{\boldsymbol{\vartheta}}(t)$ to denote a function $f(t;\boldsymbol{\vartheta})$ of time with parametric dependence on $\boldsymbol{\vartheta}$.
The goal of the present work is to provide an accurate ML model which outputs the functions $A$ and $\phi$, as generated by the state-of-the-art time domain WF models.
\par
Apart from a numerical constant, the quantity ${\tilde{h}(t; \boldsymbol{\vartheta}) = A(t; \boldsymbol{\vartheta}) e^{i \phi(t; \boldsymbol{\vartheta})}}$ is the $h = h_+ +i h_\times$ strain, generated by a BBH with orbital parameters $\boldsymbol{\vartheta}$, when observed from the direction orthogonal to the total angular momentum ($\iota =0$), at a luminosity distance $d_L = \SI{1}{Mpc}$ and with $\varphi_0 =0$.
$A(t)$ represent the amplitude of $\tilde{h}_+$ as a function of time, while $\phi(t)$ represent the phase of $\tilde{h}_+$ as a function of time.\footnote{
We could have also worked with $\mathrm{Re}{\tilde{h}}$ and $\mathrm{Im}{\tilde{h}}$. However, such choice is most prone to numerical inaccuracies: the strain is a fast oscillating function and tracking its behavior is difficult.}
\par
The set of independent orbital parameters to consider is $\boldsymbol{\vartheta} = (m_1, m_2, s_1, s_2)$ where $s_i$ is the spin magnitude of the $i$-th BH.
It is convenient to parametrize the two masses with the mass ratio $q$ and the total mass $M$:
\begin{equation} \label{eq:def_q}
	q = \frac{m_1}{m_2} >1 \qquad M=m_1+m_2
\end{equation}
with the convention that $m_1>m_2$.
\par
We now state our problem precisely. We wish to find a ML model that reliably represents the following map:
\begin{align}
	(q, M, s_1, s_2) &\longmapsto A_{(q, M, s_1, s_2)}(t) \label{eq:objective_amp}\\
	(q, M, s_1, s_2) &\longmapsto \phi_{(q, M, s_1, s_2)}(t) \label{eq:objective_ph}
\end{align}
where $A(t)$ and $\phi(t)$ are as in equation \eqref{eq:h_ML}.

\section{The model}
%
\subsection{Modelling dependence on total mass}
Before developing the full ML model, the problem (\ref{eq:objective_amp},~\ref{eq:objective_ph}) can be further simplified using the global scale invariance of general relativity in vacuum. This will allow us to model analytically the dependence on total mass $M$.
\par
Following~\cite{Arbey2019scaling}, we recognize that the free theory lacks of a built in scale. For this reason, a scale coordinate transformation $x^\mu \rightarrow \lambda x^\mu$ must not affect the physics, as long as the other quantities are scaled accordingly.
The scalings are as follows:
\par
{\footnotesize
\begin{alignat*}{4}
	&x \rightarrow \lambda x & \textrm{(distance)} \hskip0.5cm &t \rightarrow \lambda t & \textrm{(time)}\\
	&M_i \rightarrow \lambda M_i & \textrm{(mass)} \hskip0.5cm &p_i \rightarrow \lambda p_i & \textrm{(momentum)} \\
	&J_i \rightarrow \lambda J_i  & \textrm{(angular momentum)} \hskip0.5cm &s_i \rightarrow s_i & \textrm{(dimensionless spin)}\\
	&E \rightarrow \lambda E & \textrm{(energy)} \hskip0.5cm &f \rightarrow \lambda^{-1} f & \textrm{(frequency)}\\
	&h \rightarrow h & \textrm{(strain)} \hskip0.5cm &v \rightarrow v & \textrm{(velocity)} \\
\end{alignat*}
}
%This can be applied to the case of GW generated by a BBH coalescence:
%\begin{equation}\label{eq:GW_scaling}
%	h(\lambda r,\lambda t; \lambda m_1, \lambda m_2, s_1, s_2) = h(r, t; m_1, m_2, s_1, s_2)
%\end{equation}
%\par
%Factoring out the dependence on distance ($\propto \frac{1}{d_L}$) in eq.~\eqref{eq:GW_scaling}, one can find how scale invariance can be used to model the total mass dependence of amplitude $A_{\boldsymbol{\vartheta}}$ and phase ${\phi}_{\boldsymbol{\vartheta}}$:
This can be applied to the case of GW generated by a BBH coalescence to obtain the analytical total mass dependence of amplitude $A_{\boldsymbol{\vartheta}}$ and phase ${\phi}_{\boldsymbol{\vartheta}}$:
\begin{align}
	\frac{1}{M^\prime} A_{(q, M^\prime, s_1, s_2)}\left(\frac{t}{M^\prime}\right) &= 	\frac{1}{M} A_{(q, M, s_1, s_2)}\left(\frac{t}{M}\right) \label{eq:amp_scaling}\\
	{\phi}_{(q, M^\prime, s_1, s_2)}\left(\frac{t}{M^\prime}\right) &= 	{\phi}_{(q, M, s_1, s_2)}\left(\frac{t}{M}\right)  \label{eq:ph_scaling}
\end{align}
where $M$, $M^\prime$ are arbitrary total mass.
\par
Thus, in a ML model we only need to consider the parameters ${\tilde{\boldsymbol{\vartheta}} = (q, s_1, s_2)}$.
%and fit the relation ${(q, s_1, s_2) \longmapsto A_{(q, \tilde{M}, s_1, s_2)}(t)}$ (and ${\phi}_{(q, \tilde{M}, s_1, s_2)}(t)$) with a fixed $\tilde{M}$.
Once such model is fitted, one can use equations \eqref{eq:amp_scaling} and \eqref{eq:ph_scaling} to produce a waveform with arbitrary total mass.
%
\begin{figure}[!t]
	\centering
	\includegraphics[width=\columnwidth,keepaspectratio, trim = {.5cm 0cm .5cm 1cm}]{tau_grid}
	\caption{Amplitude (arbitrary units) of a GW wave represented on a grid with 30 points. On left panel, amplitude values are plotted in the reduced time grid $\boldsymbol{\tau}$ (units in $\frac{s}{M_\odot}$). On the right panel, the same function is represented as a function of the transformed grid $\boldsymbol{\tilde{\tau}}$ (units in $\left(\frac{s}{M_\odot}\right)^\alpha$).
It is set $\alpha = 0.4$.
It is manifest that $\boldsymbol{\tau}$ grid is finer around the merger. On the other hand in the transformed grid $\boldsymbol{\tilde{\tau}}$, amplitude has a smoother behaviour. 
}
	\label{fig:tau_grid}
\end{figure}
%
\subsection{The time grid}
The first task to build a waveform generator is to choose a representation of the waveforms. Each function to fit $f$ (i.e. amplitude and phase) must be represented by its values $\mathbf{f} \in \R^D$ on a discrete grid of $D$ points $\mathbf{t} \in \R^D$.
In equations~\eqref{eq:amp_scaling} and \eqref{eq:ph_scaling}, only dimensionless time $\tau=\frac{t}{M}$ appears and it is then convenient to work in a grid of reduced time $\boldsymbol{\tau}$. The time grid is chosen with the convention that at $\tau=0$ the merger happens (i.e. the amplitude has a maximum).
Both amplitude and phase are represented by:
\begin{equation}
	\mathbf{f}({\tilde{\boldsymbol{\vartheta}}})_i = f_{{\tilde{\boldsymbol{\vartheta}}}}(\boldsymbol{\tau}_i) \;\;\; 
\end{equation}
where $f$ stands for any of the functions $A_{\tilde{\boldsymbol{\vartheta}}}(t)$ and ${\phi}_{\tilde{\boldsymbol{\vartheta}}}(t)$.
\par
The value of $f$ at an arbitrary time must be found by interpolation and introduces an error in the value of the function.
To make the interpolation effective, we want a finer grid when the function changes much.
Clearly an equally spaced grid over times is not the best choice since the amplitude has a very narrow peak at $\tau=0$
\footnote{As the phase has a rather regular behavior, it is not important to choose the right grid. For this reason a single grid for amplitude and phase, tuned on the behavior of amplitude, is used.}.
A good solution is to create an equally spaced grid $\boldsymbol{\tilde{\tau}}$ for the variable
\begin{equation} \label{eq:tau_tilde}
	{\tilde{\tau}} \equiv \sign{\tau} \cdot (|\tau|)^\alpha ;\;\; \alpha < 1
\end{equation}
and build the $\tau$ grid ${\boldsymbol{\tau}}$ as:
\begin{equation} \label{eq:tau_grid}
	{\boldsymbol{\tau}}_i = \sign{\boldsymbol{\tilde{\tau}}_i} \cdot (|\boldsymbol{\tilde{\tau}}_i|)^{\frac{1}{\alpha}}
\end{equation}
We call $\alpha$ \textit{distortion parameter}.
As can be seen in figure \ref{fig:tau_grid}, this choice ensures that more points are accumulated around the merger.
\par
In this framework, our problem reduces to performing the regression:
\begin{align}
	{\tilde{\boldsymbol{\vartheta}}} = (q, s_1, s_2) \in \mathcal{P} \longmapsto \boldsymbol{A}_{{\tilde{\boldsymbol{\vartheta}}}} \in \R^D \\
	{\tilde{\boldsymbol{\vartheta}}} = (q, s_1, s_2) \in \mathcal{P} \longmapsto \boldsymbol{\phi}_{{\tilde{\boldsymbol{\vartheta}}}} \in \R^D 
\end{align}
where $\mathcal{P} \subset \R^3$ is the domain in which the physical parameters are allowed to vary.
Spins must be in range $[-1,1]$ and the mass ratio must satisfy $q>1$.
Usually, the training EOB models are calibrated for domains $\mathcal{P} \simeq [1,20]\times[-0.9,0.9]\times[-0.9,0.9]$. A conservative choice leads to use a subset of the full calibration domain.

\subsection{Dataset creation}
As in any ML method, we must create a dataset in order to perform training.
For our model, the dataset ${X \in \mathbf{Mat}(N,3+2D)}$ of $N$ waveform has the following form:
\begin{equation} \label{eq:dataset}
	X_{i:} = [q,s_1,s_2, {A}_{{\tilde{\boldsymbol{\vartheta}}}}^T, \boldsymbol{\phi}_{{\tilde{\boldsymbol{\vartheta}}}}^T]
\end{equation}
where $X_{i:}$ denotes the i-th row of the dataset matrix.
\par
The dataset is filled with random values of parameters ${\tilde{\boldsymbol{\vartheta}}}_i \sim \textrm{Unif}(\mathcal{P})$
\footnote{We denote by $\textrm{Unif}(\mathcal{P})$ a uniform probability distribution on the set $\mathcal{P}$.}.
To generate the training waves the \texttt{TEOBResumS} model is used \textbf{(CITE...)}.
Waves are generated with a standard set of parameters: $\iota =0 $, $\varphi_0 = 0$, $d_0 = \SI{1}{Mpc}$ and $M = \SI{20}{M_\odot}$.
The output of the training surrogate model must be interpolated to the chosen grid.
\par
It is important to ensure that all waves have zero phase at a constant time point $\bar{t}$. This is crucial in order to have a continuous dependence of the phase components on the orbital parameters; a random alignment would wash out any relation. Model performances are not seen to depend on the choice of $\bar{t}$.
%%%%%%%%%%%%%
\subsection{Dimensionality reduction}
Once we are able to represent waveforms, a regressions ${\tilde{\boldsymbol{\vartheta}}} \longmapsto \boldsymbol{A}_{{\tilde{\boldsymbol{\vartheta}}}}, \boldsymbol{\phi}_{{\tilde{\boldsymbol{\vartheta}}}}$ is unfeasible. The dimension of the target space is too large for this task. Luckily, the elements of $\boldsymbol{A}, \boldsymbol{\phi}$ are strongly correlated with each other: the independent amount of information, required to fully reconstruct the wave, can be stored in a low dimensional vector.
A number of ML techniques to perform such a task are available. Among them, Principal Component Analysis (PCA) \cite[ch. 12]{murphy2012machine} was found to be particularly effective.
\par
A PCA model is trained with the dataset in \eqref{eq:dataset}: it represents an (approximate) bijective map between the high dimensional waveform $\mathbf{f} = \boldsymbol{A}, \boldsymbol{\phi} \in \R^D$ and the low-dimensional representation $\mathbf{g} = \mathbf{g}_A , \mathbf{g}_\phi \in \R^K$.
Here $K$ is the dimension of low-dimensional representation.
In what follows, $\mathbf{f}$ will be the high order representation of any of the function $A_{{\tilde{\boldsymbol{\vartheta}}}}(t)$, $\phi_{{\tilde{\boldsymbol{\vartheta}}}}(t)$, while  $\mathbf{g}$ will be the PCA reduced lower order representation of $\mathbf{f}$.
The relation takes the following form:
\begin{align}
	\mathbf{g} = H (\mathbf{f} - \boldsymbol{\mu}) \label{eq:PCA_reduction_model}\\
	\mathbf{f} = H^T \mathbf{g} + \boldsymbol{\mu} \label{eq:PCA_reconstruction_model}
\end{align}
where, as usual in PCA, $H \in \mathbf{Mat}(K,D)$ is the matrix whose colums are the first K eigenvalues of the empirical covariance matrix $\Sigma = \frac{1}{N} \sum_{i=1}^N \mathbf{f}_i \mathbf{f}^T_i \in \mathbf{Mat}(D,D)$; the eigenvectors are also called principal components of the data (PCs). $\boldsymbol{\mu}$ is the empirical mean vector: ${\boldsymbol{\mu} = \frac{1}{N} \sum_{i=1}^N (\boldsymbol{f}_i)}$.
In the equations above, the ${\tilde{\boldsymbol{\vartheta}}}$ dependence is omitted for notational simplicity.
\par

%%
\subsection{Regression}
Once a dimensional reduction (and reconstruction) scheme is available, the aim is to perform the regression
\begin{equation} \label{eq:regression_model}
	{\tilde{\boldsymbol{\vartheta}}} \longmapsto \boldsymbol{g}({\tilde{\boldsymbol{\vartheta}}})
\end{equation}
A number of ML models are avaiable for this purpose. The model Mixture of Experts (MoE) \cite{Jacobs1991AdaptiveMoE} \cite[ch. 11]{murphy2012machine} is found to be a good choice.
\par
It performs the following 1D regression:
\begin{equation} \label{eq:MoE}
	y(\mathbf{x}) = \sum_{l=1}^L (W^T \mathbf{x})_l \cdot \mathcal{S}(V^T\mathbf{x})_l
\end{equation}
where $\mathcal{S}$ is the \textit{softmax function}:
\begin{equation} \label{eq:softmax}
	\mathcal{S}(V^T{\mathbf{x}})_l = \frac{e^{(V^T{\mathbf{x}})_l}}{\sum_{l^\prime = 1}^L e^{(V^T{\mathbf{x}})_{l^\prime}}}
\end{equation}
and ${\mathbf{x}} \in \R^{\tilde{M}}$ and $V,W \in \mathbf{Mat}(\tilde{M},L)$.
The meaning of eq.~\eqref{eq:MoE} is clear: the output is a weighted combination of $L$ linear regressions $(W^T \mathbf{x})_l$ (each called an \textit{experts}); each expert perform a reliable regression in a small region of the space. The softmax function (in this context also called \textit{gating function}) switches on the expert contributions whenever this is required.
MoE is usually fitted with the Expectation Maximization (EM) algorithm, which iteratively sets the $W$ and $V$ by refining a lower bound to the log-likelihood of the model.
\par
Linear regression is a very simple model, often inadequate to model a complex relation. A simple trick to improve its performance is called \textit{basis functions expansion}. It consist in the replacement:
\begin{equation}
	{\mathbf{x}} \longrightarrow {\boldsymbol{\xi}}({\mathbf{x}}) = [\xi_1({\mathbf{x}}), \ldots, \xi_M({\mathbf{x}})]^T
\end{equation}
Thus, each expert becomes a non linear regression of the input ${\mathbf{x}}$.
A careful choice of basis functions can really make a difference in fit performances and it must be done at validation time, by comparing performances of different models.
\par
In our model, including in the $\xi_i$ every monomial up to 3/4th order in the three variables $ (\log q, s_1, s_2)$ is a good working choice
\footnote{
The choice of working with variable $\log q$ rather than $q$ gives much better validation results.
Heuristically, using $\log q$ prevents the values of the data features to vary too much within the range of interest, yielding more stable numerical performance.
}.
\par
The MoE is fitted with a reduced dimensional version of dataset~\eqref{eq:dataset}:
\begin{equation} \label{eq:dataset_MoE}
	G_{i:} = [q,s_1,s_2, \mathbf{g}_{A}(\tilde{\boldsymbol{\vartheta}})^T, \mathbf{g}_{\phi}(\tilde{\boldsymbol{\vartheta}})^T]
\end{equation}
The user must choose the number $L$ of experts to use and the basis functions features ${\boldsymbol{\xi}}({\tilde{\boldsymbol{\vartheta}}}) \in \R^{M}$ to use.
\par
As MoE model deals with single dimensional outputs, a single independent regression must be performed for each component $g_k$ of $\mathbf{g} \in \R^K$
\footnote{This is not a great limitation, because, due to orthogonality of PCs, each $g_j$ is independent from the other: we do not miss correlation among different regressions.}.
In general, a regression will be a collection of MoE weights ${\{ W^{(k)}, V^{(k)} \in \mathbf{Mat}(M,L_k) \}_{k=0}^K}$, where index $k$ labels different regressions for each PC.

\subsection{Summary}
The model has the following explicit form:
\begin{align}
	& \textrm{model}: \mathcal{P} \subset \R^3 \rightarrow \R^K \rightarrow \R^D \nonumber\\
	& {\tilde{\boldsymbol{\vartheta}}}
	\longmapsto  \mathbf{g}({\tilde{\boldsymbol{\vartheta}}} ) = 
		\begin{pmatrix}
		\sum_{l=1}^{L_1} (W^{(1)\;T} \boldsymbol{\xi})_l \cdot \mathcal{S}(V^{(1)\;T}\boldsymbol{\xi})_l \\
		\vdots \\
		\sum_{l=1}^{L_K}  (W^{(K)\;T} \boldsymbol{\xi})_l \cdot \mathcal{S}(V^{(K)\;T}\boldsymbol{\xi})_l
		\end{pmatrix}
	\nonumber \\	
	& \qquad \qquad \qquad \longmapsto \mathbf{f}({\tilde{\boldsymbol{\vartheta}}} ) = H^T \mathbf{g}({\tilde{\boldsymbol{\vartheta}}} ) + \boldsymbol{\mu} \label{eq:model}
\end{align}
where ${\boldsymbol{\xi}}({\tilde{\boldsymbol{\vartheta}}}) \in \R^M $ are the chosen basis function for the regression and $\mathcal{S}(\cdot)_k$ is the \textit{softmax} function eq~\eqref{eq:softmax}.
Two relations of the same type must be fitted, one for the amplitude, the other for the phase.
\par
Once weights are set properly, the expression provides an estimation for the waveform $\tilde{h}$ in \eqref{eq:h_std} and \eqref{eq:h_ML}.
The fitted expression for  $\tilde{h}$ is evaluated at constant mass $M = \SI{20}{M_\odot}$; the dependence on total mass must be included with equations~\eqref{eq:amp_scaling} and \eqref{eq:ph_scaling}.
The dependence on $(d_L, \iota, \varphi_0)$ is computed with eq.~\eqref{eq:h_parametrization_simple}.
With this method, we are able to obtain a complex waveform $h(t;m_1,m_2, s_1, s_2, d_L, \iota, \varphi_0)$ which reproduces closely a waveform from the training surrogate model.
\par
A Python implementation of the model is released in the package \texttt{mlgw}, publicly available at \href{https://pypi.org/project/mlgw/}{pypi.org/project/mlgw/}. The user can install it with the command \texttt{pip install mlgw}.
The package provides also the gradients $\frac{\partial h}{\partial \vartheta_i}$ of the waveform.
\par
The model can generate a waveform also for $\tilde{\boldsymbol{\vartheta}} \notin \mathcal{P}$, without guarantee to provide a reliable result.
The waveform can be evaluated on a user given time grid by means of interpolation; the grid must ensure that the peak of amplitude happens at $t=0$.
If the user asks for an extrapolation outside the dataset time grid, the model returns $h = 0$.
\par
Roughly, the minimum frequency in the signal as a function of $M, q$ and $\tau_{min}$ is given by:
\begin{align}\label{eq:f_min}
	f_{min} =
	\SI{151}{Hz}  \left( \frac{(1+q)^2}{q} \right)^{\frac{3}{8}}  \left( \frac{M_\odot}{M} \right)  \left(\frac{\SI{1}{ \frac{s}{M_\odot}}}{\tau_{min}} \right)^{\frac{3}{8}}  
\end{align} 
The expression is approximate because it is obtained within a Newtonian framework and does not consider spin effects.
\par

%%%%%%%%%%%%%%%%%%
\section{Model performance}
We now discuss some tests on our model. We first study how its performance depends on the choice of hyperparameters. Furthermore, we assess the model accuracy and its limitations.
Finally, we measure the speed up provided by our model as compared with standard EOB methods.
As it is common, we measure the similarity between two waves by means of the \textit{optimal mismatch}:
\begin{align}
	\mathcal{F}[h_1,h_2] &\equiv \argmin_{\phi_0} \left[ 1- \frac{\langle h_1, h_2 e^{i\phi_0} \rangle}{\sqrt{\langle h_1, h_1 \rangle \langle h_2, h_2 \rangle}} \right]	\label{eq:mismatch_def} \\
	& = \argmin_{\phi_0} \left[ 1- \frac{ \mathrm{Re} \int \d{f} \; \frac{\tilde{A}_1 \tilde{A}_2}{S_n} e^{i(\phi_1-\phi_2-\phi_0)}}
		{\sqrt{\left(\mathrm{Re} \int \d{f} \; \frac{\tilde{A}_1^2}{S_n}\right)
		\left( \mathrm{Re} \int \d{f} \; \frac{\tilde{A}_2^2}{S_n} \right)}} \right] \nonumber
\end{align}
%%%%%%%
\subsection{Validation}
Wherever relevant, we will employ a dataset with $5800$ waveforms generated in the domain $\mathcal{P} = [1,20]\times[-0.8,0.95]\times[-0.8,0.95]$, with $\tau_{min} = \SI{1.0}{s/M_\odot}$. The dataset was generated with TEOBResumS model \cite{}.
\paragraph{Dataset generation parameters}
We first evaluate the impact of number of grid points $N_{grid}$ and distortion parameter $\alpha$.
Let $\mathbf{f}_{N_{grid}, \alpha}$ the wave stored in a dataset where $\tau_{min}$ and $\mathcal{P}$ are fixed as above. We compare it with the output of the EOB model $\mathbf{f}_{EOB}$.
To compare the two waves, $\mathbf{f}_{N_{grid}, \alpha}$ must be evaluated on the dense time grid of EOB, by means of linear interpolation.
We then vary $N_{grid}$ and $\alpha$ and compute the resulting mismatch $\mathcal{F}[\mathbf{f}_{EOB}, \mathbf{f}_{N_{grid}, \alpha}]$.
We report the results in figure \ref{fig:N_grid}.
%%
\begin{figure}[!t]
	\centering
	\includegraphics[width=\linewidth,keepaspectratio]{N_grid}
	\caption{Mismatch between waves $\mathbf{f}_{N_{grid}, \alpha}$ and raw waves from EOB model, as a function of time grid size $N_{grid}$. Each series refers to a different values of $\alpha$.
Mismatch is computed on $10$ test waves.
%The raw wave from EOB is evaluated at the original time grid provided by EOB: this means that it spans $\sim \SI{4}{s}$ sampled at $10^5$ step per second.
}
	\label{fig:N_grid}
\end{figure}
\par
As expected, we note that, by increasing the number of grid points, the mismatch decreases. Furthermore, using more than $\sim 10^3$ grid points, does not bring any improvement to mismatch. The result is dominated by numerical errors in the interpolations and it provides a lower-bound for the performances of the fit.
We note that a dataset grid with $\alpha\simeq 	0.35-0.5$ is a good choice.
It is effective if $N_{grid}$ does not grow too much. For a high number of grid points, different values of $\alpha$ yield almost equivalent results.
A good setting for dataset hyperparameters could be: $N_{grid} \simeq 2/3 \cdot 10^{3}$ and $\alpha \simeq 0.3/0.5$.
%%%%
\begin{figure}[!t]
	\centering
    \begin{minipage}{.5\linewidth}
        \centering
        \includegraphics[width=\linewidth]{MoE_mismatch_amp}
    \end{minipage}\hfill
    \begin{minipage}{.5\linewidth}
        \centering
        \includegraphics[width=\linewidth]{MoE_mismatch_ph}
    \end{minipage}
	\caption{Validation results for fit of MoE model. Each point corresponds to a MoE regressions for the amplitude (left) and phase (right), with a different values of expert number $N_{exp}$ and order of polynomial basis function.
The amplitude and phase are represented with 5 and 4 PCs respectively.
In the colorbar, we represent the mismatch on test waves: it is obtained by reconstructing test waves with fitted amplitude (phase) and test phase (amplitude).
}
	\label{fig:MoE_test}
\end{figure}


\paragraph{MoE parameters}
In what follows, we will focus on setting a small number of hyperparameters relevant to MoE model: the number of experts $N_{exp}$ for each component model, the basis functions $\xi_i(\boldsymbol{\tilde{\vartheta}})$ to use in basis function expansion and the number $N_{train}$ of training points to use.
Other parameters, related to the details of the training procedure, will not be considered.
\par
In figure \ref{fig:MoE_test} we show our results.
We fitted a model for amplitude (or phase) for different configurations of expert number $N_{exp}$ and polynomial basis function.
By label "n-th order", we mean that in the basis function expansion, every monomial up to n-th order is used.
We report with a colorbar the value of the mismatch $F$ between test and reconstructed WFs. The MoE models for each component share the same number of experts $N_{exp}$.
The test mismatch for the fitted amplitude (phase) is computed by using the test phase (amplitude) in the reconstructed wave.
\par
Interpretation of the results is straightforward. Fit performances improves, as the model complexity (i.e. number of fittable parameters) increases.
In general, we note that adding more features (i.e. improving expert's flexibility) is more effective than increasing the number of experts.
However, model performances do not improve indefinitely. As model complexity increases beyond a threshold, performance does not get any better.
Such threshold is around a model with 4 experts and 4th order polynomial regression. This "simple" model match the performances of much more complex models and thus it should be deemed as the best choice.
%%%%%%%%%
\begin{figure}[!t]
	\centering 
    \begin{minipage}{.5\linewidth}
		\centering
	    \includegraphics[width=\linewidth]{mismatch_MoE_vs_PCA_amp}
	\end{minipage}\hfill
    \begin{minipage}{.5\linewidth}
		\centering
	    \includegraphics[width=\linewidth]{mismatch_MoE_vs_PCA_ph}
	\end{minipage}
	\caption{Test mismatch as a function of the number of PCs used in the low dimensional representation.
Label "PCA" refers to waves reconstructed with PCA only; points with label "MoE" are reconstructed after a MoE regression.
Data refers to amplitude (left panel) and phase (right panel).
MoE model is chosen to be the optimal one with $4$ experts and a fourth order polynomial.
}
	\label{fig:mismatch_MoE_vs_PCA}
\end{figure}
%%%%%%%%%
\paragraph{Choosing the number of PCs}
Of course, the accuracy of the reconstruction of the low dimensional representation depends on the number $K$ of principal components considered: the more PCs are used, the best accuracy can be achieved.
However in practice, due to error in the MoE regression, one cannot reduce the reconstruction mismatch arbitrarily and should not choose the number of PCs to fit before having seen the MoE accuracy.
At high PC order the relations to fit become noisy and the regression becomes less accurate, eventually washing out any improvement brought by a higher number of PCs.
\par
In figure \ref{fig:mismatch_MoE_vs_PCA} we report a numerical study of this. We plot the reconstruction mismatch as a function of the number of PCs considered. We consider separetely regression for the amplitude and for the phase. In one series, we reconstruct the wave using true values of PCs: the mismatch is a measure of PCA accuracy. In the other series, we reconstruct a wave using values for PCs as guessed by MoE regression: this is a measure of accuracy of both PCA and regression.
For the first two PCs, the regression is accurate enough for reproducing the PCA accuracy.
On the other hand, any regression beyond the 4th PCA component does not give any improvement to the MoE mismatch: the noise in the relation of high order PCs is too high for a regression to be performed.
\par
In the PCA, we include every PC which yields improvement in MoE mismatch. For our model, $K = 5(4)$ is a good choice for amplitude (phase).
Of course, this strongly depends on the regression model: the more precise the model is, the more PCs can be included.
However, any model cannot increase its accuracy indefinitely. Every surrogate model has an intrinsic noise level, due to numerical error and to the approximations in the physical model.
%%%%%%%%%%%%%
\paragraph{Choosing the number of training points}
The choice of the number of training points $N_{train}$ must trade between accuracy and speed of execution. Too many training points will make the training slow and unfeasible, while too few training points will yield a poor model, which does not generalize data (underfitting).
In the choice of number of training points, the comparison between train and test error will provide important information on how the model is able to generalize the trend.
\par
In figure \ref{fig:N_train} we report train and test value of mismatch and mse of first 3 PCs as a function of the number of training points. Data refers to a MoE model fitted for 4 PCs of the phase dataset. The models has ${N_{exp} = 4}$ and performs basis function expansion with a fourth degree polynomial. Test mismatch are obtained using test amplitude to reconstruct the waveform; this is not a great limitation as any error in phase reconstruction dominates the overall mismatch (see e.g. fig.~\ref{fig:mismatch_MoE_vs_PCA}).
\begin{figure}
	\centering
    \includegraphics[width=\linewidth]{N_train}
	\caption{Train and test error for MoE fit of 4 PCs of phase, as a function of the number of training points. We report train and test reconstruction mismatch (top) and mse for the first 3 PCs (below).
    MoE model employs 4 experts and a fourth order polynomial for a basis function expansion.
    }
	\label{fig:N_train}
\end{figure}
\par
As $N_{train}$ increases, we see a steady decrease of the errors, until a plateau is reached.
We note that overfitting is not a problem. For a reasonably high number of training points ($N_{train} \gtrapprox 50$) train and test error are close to each other.
For $N_{train} \gtrapprox 800$, the trend stabilises and increasing training points does not affect much model performance.
In the present model, setting $N_{train} \simeq \SI{3000}{}$ is a good choice
\footnote{As compared with standard neural networks, which routinely employ $O(10^5)$ points datasets, this is an incredibly low amount of data. This is due to the fact that MoE is a simple model with a few number of parameters: few data are enough for learning a reliable relation.}.
%%%%%%%%%%%%%%%%%%%%%%
\subsection{Accuracy}
%%%%
\begin{figure}
	\centering
    \includegraphics[width=\linewidth]{F_hist}
	\caption{Histogram for the logarithm of mismatch values, computed on $N=4000$ test waveforms. Each WF is generated with random orbital parameters $(m_1,m_2, s_1, s_2, d_L, \iota, \phi_0)$ and with a starting frequency of $\SI{10}{Hz}$.
We report the median value $q_{50\%}$ as well as the positions $q_{5\%}$ and $q_{95\%}$ of the 5th and 95th percentile.
The median values, with $90\%$ confidence interval, are: $m_{\SI{5}{Hz}} = ??^{+??}_{-??}$ and $m_{\SI{20}{Hz}} = ??^{+??}_{-??}$.
\textbf{Why the mismatch gets so bad when including inclination? Is it normal or is there a mistake? Anyway, in every paper, when givin the mimsmatch between models, nobody include the inclination; should we do the same?? We would obtain far better results, which btw would be comparable with the other papers...}
}
	\label{fig:F_hist}
\end{figure}
%%%%
\paragraph{Test mismatch}
We compute mismatch value on a number of randomly generated waves.
The mismatch is computed with a flat noise curve, i.e. a constant power spectral density for the detector noise.
In order to tests the model in the most general case, we extract a random values of the physical parameters (i.e. $m_1,m_2, s_1, s_2, d_L, \iota, \varphi_0$) for each wave.
We report our results in the histogram in figure~\ref{fig:F_hist}.
We report a median value of the distribution $\mathcal{F}_m = 4 \cdot {10^{-3}}^{+???}_{-???}$. Such results are similar to the discrepancies between state-of-the-art models.
\par
To understand better model performances, it is interesting to display the accuracy as a function of the orbital parameters $\boldsymbol{\vartheta} = (q,M,s_1,s_2)$.
We generate waves for randomly chosen values of $\vartheta = (q, M, s_1, s_2)$ and, for each wave, we measure test mismatch $\mathcal{F}$ and mse on the reconstruction of the first PC for the phase.
The latter is useful to test the accuracy of the fit before wave reconstruction.
The results are reported in the contour plots in figure \ref{fig:countour}.
\par

%%
\afterpage{
\begin{figure}[!ht]
	\newcommand{\minipagesize}{.5}
	\centering 
    \begin{minipage}{\linewidth}
        \centering
	 	\begin{minipage}{\minipagesize\linewidth}
		    \centering
		    \includegraphics[width=\linewidth]{F_countour_mass}
		\end{minipage}\hfill
		\begin{minipage}{\minipagesize\linewidth}
		    \centering
		    \includegraphics[width=\linewidth]{mse_countour_mass}
		\end{minipage}
    \end{minipage}\hfill
    \begin{minipage}{\linewidth}
        \centering
	 	\begin{minipage}{\minipagesize\linewidth}
		    \centering
		    \includegraphics[width=\linewidth]{F_countour_spins}
		\end{minipage}\hfill
		\begin{minipage}{\minipagesize\linewidth}
		    \centering
		    \includegraphics[width=\linewidth]{mse_countour_spins}
		\end{minipage}
    \end{minipage}\hfill
    \begin{minipage}{\linewidth}
        \centering
	 	\begin{minipage}{\minipagesize\linewidth}
		    \centering
		    \includegraphics[width=\linewidth]{F_countour_q_s1}
		\end{minipage}\hfill
		\begin{minipage}{\minipagesize\linewidth}
		    \centering
		    \includegraphics[width=\linewidth]{mse_countour_q_s1}
		\end{minipage}
    \end{minipage}
	\caption{We report test mismatch and mse for the first PC of the phase, as a function of the orbital parameters $\vartheta = (q, M, s_1, s_2)$. The histograms holds $145061$ waveforms, randomly drawn by varying the relevant parameters.
In the left column, the color mesh refers to test mismatch; in the right column, we report test mse.
On the x-y we display values of two physical quantities, each discretized in $35$ bins.
On top row, we display $q$ vs $M$ dependence. On central row, we present spins dependence ($s_1$ vs $s_2$). On bottom row, we show $q$ vs $s_1$ dependence.
Each wave starts $\SI{8}{s}$ before merger.
}
	\label{fig:countour}
\end{figure}
%\clearpage
}
%%%
\par
By looking at the top line of \ref{fig:countour}, we note that the mse does not depend on $M$. This was to be expected because the total mass dependence is inserted analytically within the model.
%However, we observe that, at constant $q$, at lower $M$ values, the mismatch is higher. This is explained on physical basis. In the Newtonian approximation $\phi(t) \sim M^{-5/8}$ for constant time to merger. Thus If $M$ is small, the value for phase is high: the two waves have more cycles to "accumulate mismatch".
\par
Again on the top line, we note that both $\mathcal{F}$ and mse depend (quite strongly) on $q$.
The mismatch and mse are well correlated: the reconstruction of the wave and the interpolation do not affect much the mismatch.
We note that for low values of $q$ the fit shows poor performance: in that region the relation to catch is less smooth, making the regression less reliable.
\par
In the center line of \ref{fig:countour}, we displayed the dependence on spins.
As long as the $s_1$ dependence is considered, the most striking feature is the inverse correlation of mismatch and mse for the first phase PC.
This means that the value of the first PC does not affect much the spin dependence of the waveform and that, being non-leading, spin contribution become important at lower order of PCs.
Indeed, the values of the first PC are well correlated with mismatch in the case of $q$. See~\cite{Ohme2013PCA_GW} for a closely related discussion on PCA components and its dependence on physical parameter.
\textbf{Is it fine to cite this? Is it relevant?}
\par
Apart from this feature, we note that the mismatch tends to grow for high spins: the fit is less reliable in such regions.
\par
In the third row of \ref{fig:countour}, we displayed the dependence on $q$ and $s_1$, the variables on which the error depends more.
We note again the inverse correlation between the mismatch and mse, when considering the $s_1$ dependence.
%%%%%%%%%%%%%%%%%%
\paragraph{Parameter estimation}
We run a PE on the signal GW150914 \cite{Abbott2016GW150914}.
We performed a sampling from the posterior of the signal with a Nested Sampling algorithm \cite{skilling2006nested_sampling} \cite{Aasi:2013jjl}.
Besides a set of sampled points, the algorithm provides an estimation of the Bayes factor for the model\footnote{The Bayes factor $\mathcal{B}=\frac{Z_z}{Z_n}$ is the ratio between the evidence of the model $Z_s$, where data are assumed to be a superposition of GW signal and noise, and the evidence $Z_n$ of the noise model, where data are assumed to be composed only by noise. It measures framework the probability that the WF model explain the data.}.
We plot some (marginalized) posterior probability distribution functions (PDF) in figures~\ref{fig:PDF_BBH}.
In table \ref{tab:PE_results}, we report our physical predictions for the source parameters and a number of other quantities and we compare them with the published LIGO-Virgo results in \cite{Abbott_2016_GW150914prop}.
\par
\begin{table}
	\centering
	\footnotesize
	\def\arraystretch{1.5}
	\begin{tabular}{ l @{\hspace{2em}} c @{\hspace{2em}} c@{\hspace{0em}} }
										  & LIGO-Virgo & mlgw \\ 
	\hline \hline
		 Total mass $\mathcal{M}_c (M_\odot)$ & $70.3^{+5.3}_{-4.8}$ & $74.2^{+4.5}_{-4.8}$ \\ 
	\hline
		 Chirp mass $\mathcal{M}_c (M_\odot)$ & $30.2^{+2.5}_{-1.9}$ & $32.0^{+1.9}_{-2.4}$  \\ 
	\hline
		 Primary mass $m_1 (M_\odot)$ & $39.4^{+5.5}_{-4.9}$ & $40.6^{+5.4}_{-4.0}$  \\ 
	\hline
		 Secondary mass $m_2 (M_\odot)$ & $30.9^{+4.8}_{-4.4}$ & $33.6^{+5.4}_{-4.1}$  \\ 
	\hline
		 Inverse mass ratio $\bar{q}= \frac{1}{q} = \frac{m_2}{m_1}$ & $0.79^{+0.18}_{-0.19}$ & $0.83^{+0.15}_{-0.21}$\\  
	\hline
		 Effective spin parameter $\chi_{eff}$ & $-0.09^{+0.19}_{-0.17}$ & $-0.08^{+0.13}_{-0.17}$     \\
	\hline
		 (dimensionless) spin $s_1$ & $0.32^{+0.45}_{-0.28}$ & $0.14^{+0.51}_{-0.66}$    \\
	\hline
		 (dimensionless) spin $s_2$ & $0.57^{+0.40}_{-0.51}$ & $-0.02^{+0.78}_{-0.59}$   \\
	\hline
		 Luminosity distance $d_L (Mpc)$ & $390^{+170}_{-180}$ & $490^{+158}_{-208}$   \\
	\hline
		 Final mass $M_f (M_\odot)$ & $67.1^{+4.6}_{-4.4}$ & $70.5^{+3.9}_{-4.2}$  \\
	\hline
		 Final spin $s_L (M_\odot)$ & $0.67^{+0.06}_{-0.08}$ & $0.70^{+0.05}_{-0.08}$ \\
	\hline
		 Log Bayes factor $\log\mathcal{B} = \log \frac{Z_s}{Z_n}$ & $288.7^{+0.2}_{-0.2}$ & $302^{+0.2}_{-0.2}$ \\
	\hline \hline
	\end{tabular}
	\caption{Several physical quantities extracted from signal GW150914 by sampling the posterior distribution.
Results of \texttt{mlgw} model are compared by those published by the LIGO-Virgo collaboration (using EOB model) \cite{Abbott2016propGW150914}.
We report the measures (i.e. the median value of the marginalized posterior) and their $90\%$ confidence interval.
The final BH mass and spins are obtained with the formula from \cite{JimenezForteza2016fit_final_BH}.
}
	\label{tab:PE_results}
\end{table}
\par
%%%%%%
\begin{figure}
	\centering
    \includegraphics[width=.75\linewidth, trim = {3cm 0cm 3cm 0cm}]{img/intrinsic.pdf}
	\caption{
Marginalized posteriors for the chirp mass $\mathcal{M}_c$, inverse mass ration $\bar{q}=\frac{1}{q}$ and spins $s_1, s_2$ for GW150914. We report the histograms for the one dimensional posteriors of each quantity; the dashed lines reports the median value as well as the $68\%$ credible interval.
In the contour plots, we report the two dimensional posteriors for each pair of quantities.
The figure holds $16411$ samples and is generated with Python package \texttt{corner} \cite{pycorner}.
}
	\label{fig:PDF_BBH}
\end{figure}
%%%%%%%%%%%%
%%%%%%
\begin{figure}
	\centering
    \includegraphics[width=.75\linewidth, trim = {3cm 0cm 3cm 0cm}]{img/extrinsic.pdf}
	\caption{
Marginalized posteriors for the sky position angles, luminosity distance, time of coalescence and cosine of the inclination of the orbital plane for GW150914. We report the histograms for the one dimensional posteriors of each quantity; the dashed lines reports the median value as well as the $68\%$ credible interval.
In the contour plots, we report the two dimensional posteriors for each pair of quantities.
The figure holds $16411$ samples and is generated with Python package \texttt{corner} \cite{pycorner}.
}
	\label{fig:PDF_BBH_extrinsic}
\end{figure}
%%%%%%%%%%%%
We note that the predictions of \texttt{mlgw} are consistent with those of the LIGO-Virgo collaboration.
The mass related parameters (i.e. chirp mass, total mass and individual masses) are very close to their reference value.
The same happens for luminosity distance and for the final BH mass and spins.
\par
Despite being compatible with the reference values due to high uncertainties, the predicted values for the spins are rather different from the LIGO-Virgo reference values.
Indeed, the measurement of individual spins are difficult due to spin degeneracy of the waveform, as explained in \cite{Baird2013spin_degeneracy} \cite{Purrer2015meas_spin_deg} with a study of the PN waveform.
As a consequence, only the effective spin parameter ${\chi_{eff} = \frac{m_1 s_1 + m_2 s_2}{M}}$ can be reliably measured.
In fact, the two measures of $\chi_{eff}$ agree well with each other: a further confirmation of \texttt{mlgw} accuracy.
The same feature can be observed on the probability distribution $p(s_1,s_2|\mathcal{D})$ in figure~\ref{fig:PDF_BBH}: individual spins are poor constrained but the ``slope" of their correlation (i.e. the effective spin parameter) is well measured.
\par
We note that our model slightly overestimates the value of the BHs masses. This feature was already noted for a PE run with \texttt{TEOBResumS}. The fact that we obtain the same result means that \texttt{mlgw} is able to recover with details the training model.
\par
Finally, we see that the two Bayes factors are similar: the Bayesian analysis assigns to both a similar probability that the GW150914 is actually described by the model.
However, the evidence for \texttt{mlgw} appears to be slightly higher: probably, our priors cover a smaller region than that in the LIGO-Virgo analysis.
\par
%%%%%%%%%%%%%%%
\subsection{Runtime analysis} \label{sec:runtime}
Whean dealing with a real detection scenario, we are often interested in generating a WF which starts from a given frequency $f_{min}$, which is usually set by the detector's sensitivity window.
Thus, it is crucial to measure the speed up that our model can provide in performing such task.
We make a comparison with both \texttt{TEOBResumS} (the train model and the state-of-the-art in accuracy) and \texttt{SEOBNRv4\_ROM} (the state-of-the-art in time performance).
We define the speed up $\mathcal{S}$ as the ratio between the runtime of benchmark model and the runtime of \texttt{mlgw} to produce the a waveform starting from a given $f_{min}$. Each waveform is produced with constant total mass $M = 100 M_{\odot}$ and random parameters; the WF is sampled at $f_{sam} = \SI{2048}{Hz}$.
We consider the two cases with $f_{min} = \SI{5}{Hz}$ and $f_{min} = \SI{20}{Hz}$; the first choice refers to the hypotetical lower bound for the sentivity of the Einstein telescope (ET), while the second is close to that of Advanced-LIGO/Virgo.
%%
\paragraph{Comparison with \texttt{TEOBResumS}}
In figure~\ref{fig:time_performance_hist} we report the histogram of the measured speed up values for model \texttt{TEOBResumS}.

\newcommand{\factor}{.9}
\begin{figure}
	\centering
	\begin{minipage}{\factor\linewidth}
	    \includegraphics[width=\linewidth]{time_performance_hist_5}
	\end{minipage}\hfill
	\begin{minipage}{\factor\linewidth}
	    \includegraphics[width=\linewidth]{time_performance_hist_20}
	\end{minipage}

	\caption{
Histogram for values of the speed up given by \texttt{mlgw}, as compared with \texttt{TEOBResumS} model, computed on $N=2000$ test waveforms. Each WF is generated with random physical parameters and has a minimum frequency of $\SI{5}{Hz}$ (top panel) and $\SI{20}{Hz}$ (bottom panel).
We set a constant total mass $M=\SI{100}{M_\odot}$ and the sampling rate $f_{sam} = \SI{2048}{Hz}$.
We report the median value $q_{50\%}$ as well as the positions $q_{5\%}$ and $q_{95\%}$ of the 5th and 95th percentile.
The median values, with $90\%$ confidence interval, are: $m_{\SI{5}{Hz}} = ??^{+??}_{-??}$ and $m_{\SI{20}{Hz}} = ??^{+??}_{-??}$.
\textbf{Do we really want to include the actual values?? We already wrote them on the plot...}
\textbf{Are you really sure that two peaks are fine?? Check better and check again!!!}
}
	\label{fig:time_performance_hist}
\end{figure}
%%%%%%%%%%
\begin{figure}
	\centering
	\begin{minipage}{\factor\linewidth}
	    \includegraphics[width=\linewidth]{time_performance_hist_ROM_5}
	\end{minipage}\hfill
	\begin{minipage}{\factor\linewidth}
	    \includegraphics[width=\linewidth]{time_performance_hist_ROM_20}
	\end{minipage}

	\caption{
Histograms for values of the speed up given by \texttt{mlgw}, as compared with ROM model \texttt{SEOBNRv4\_ROM}, computed on $N=2000$ test waveforms. Each WF is generated with random physical parameters and has a minimum frequency of $\SI{5}{Hz}$ (top panel) and $\SI{20}{Hz}$ (bottom panel).
We set a constant total mass $M=\SI{100}{M_\odot}$ and the sampling rate $f_{sam} = \SI{2048}{Hz}$.
We report the median value $q_{50\%}$ as well as the positions $q_{5\%}$ and $q_{95\%}$ of the 5th and 95th percentile.
The median values, with $90\%$ confidence interval, are: $m_{\SI{5}{Hz}} = ??^{+??}_{-??}$ and $m_{\SI{20}{Hz}} = ??^{+??}_{-??}$.
}
	\label{fig:time_performance_hist_ROM}
\end{figure}

%%%%%%%%%%
We see that in both cases a substantial speed up is achieved. The speed up is higher for longer WFs
\footnote{This is clearly understood: a longer WF requires more computation for a EOB model, while roughly the same amount of work is done by mlgw}, 
making our model particulary convenient for advanced detectors, with a larger sensitivity window.
\par
\paragraph{Comparison with \texttt{SEOBNRv4\_ROM}}
In figure~\ref{fig:time_performance_hist_ROM} we report the histogram of the measured speed up values for model \texttt{SEOBNRv4\_ROM}.
As the ROM model yields WFs in frequency domain, in the time comparison we included a fast Fourier trasform (FFT) of the time domain WF of \texttt{mlgw}. This is to ensure that we evaluate the two model at the same conditions.
We note the the performances are quite similar to each other.
The performances of \texttt{mlgw} worsen for the $\SI{5}{Hz}$ case because more grid points are included in the computation, which results in less efficient generation.
If a lower sampling rate is employed, \texttt{mlgw} outperforms \texttt{SEOBNRv4\_ROM}.
\par
However, it is important to stress that \texttt{mlgw} is written in pure Python, while \texttt{SEOBNRv4\_ROM} is coded in C. Thus, the fact the the two models show similar performances is remarkable: surely, a C implementation of \texttt{mlgw} would be faster than \texttt{SEOBNRv4\_ROM}.
Furthermore, \texttt{mlgw} is more efficient in reconstructing the waveforms: it requires only $O(5\cdot 10^3)$ WFs for the training, while in order to build a ROM as many as $O(5\cdot 10^5)$ WFs are required.
\par
%%%
\paragraph{Profiling}
It is interesting to have a knowledge of the time spent by \texttt{mlgw} in each stage of the WF generation procedure.
We generate $100$ waves and we measure the CPU time spent to execute each basic task.
In table \ref{tab:profiling}, we compare the results for two values of $N_{grid}$.
\begin{table}
	\def\arraystretch{1.5}
	\begin{tabular}{ l c c }
		\multirow{2}{*}{Task}& \multicolumn{2}{c}{CPU time (ms)}\\
			&$N_{grid} = 10^3$	& $N_{grid} = 10^5$\\
	\hline \hline
		 Generation of raw WF 			& $7.0 \; (40.8\%)$	& $7 \; (1.2\%)$ \\ 
	\hline
		 Interpolation to the user grid & $6.2 \; (36.4\%)$	& $217 \; (37.7\%)$ \\ 
	\hline
		 Post processing 				& $2.3 \; (13.7\%)$	& $320 \; (55.5\%)$ \\
	\hline
		 Total							& $17.1 \; (100\%)$ &  $578 \; (100.0\%)$ \\
	\hline \hline
	\end{tabular}
	\caption{
Time taken by different stages of the generation of $100$ waveforms; data refers to two different values of $N_{grid}$.
Generation of raw WF refers to the computation of the strain $\tilde{h}$ as produced by a ML model. Interpolation to user grid evaluates the WF on the grid chosen by the user. In the post-processing phase, the dependence on $d_L$, $\iota$ and $\varphi_0$ is included.
}
	\label{tab:profiling}
\end{table}
\par
We see that the cost of generating the raw WF does not depend on the number of grid points. The interpolation and the post processing depends on $N_{grid}$ and their cost grows dramatically as the user requires more and more points.
It is important to stress that the latter two tasks are slow only because they deal with a huge amount of data. Indeed they perform trivial and ``quick" operations and their execution relies on well optimized \texttt{numpy} routines.
If such huge amount of datapoints is required, very little space is left for speed up.
\par

%%%%%%%%%%%%%%%%%%%
\section{Final remarks and future prospects}
We built a ready-to-use Machine Learning model which generates the gravitational wave signal from a binary Black Hole coalescence. The code is released as the package \texttt{mlgw} available via the \texttt{PyPI} Python package repository. 
Our model was built for the case of aligned spins (i.e. the non precessing case) and returns a wave given the BH's masses $m_1, m_2$ and (dimensionless) spins $s_1, s_2$ taking into account the correct dependence on source luminosity distance $d_L$, inclination angle $\iota$ and reference phase $\varphi_0$.
Our model shows excellent agreement with the underlying training set. At test times the median mismatch is $\bar{\mathcal{F}}\sim 5 \cdot 10^{-3}$. Lastly, the generation time from \texttt{mlgw} is smaller than the underlying training model by a factor of $\sim ????$, for a waveform starting at a frequency of $\SI{5}{Hz}$.
\texttt{mlgw} performance matches closely those of a ROM, which is the state-of-the-art for a quick generation.
\par
Remarkably, we discovered that a PCA is able to reproduce a high dimensional wave using a few number of variables. As for the regression model itself, the MoE model, currently it is the ``bottleneck" of the model accuracy. For this reason, we explored several alternative regression methods, including neural networks, but none of them showed better performance.
Note that underfitting may be an issue whenever the training model shows intrinsic noise due to mis-modeling, e.g. relations that are supposed to be continuous are not, or even due to poor numerical integration schemes.
\par
Our work opens up interesting opportunities in GW data analysis.
As shown in fig.~\ref{fig:time_performance_hist}, the model is the most useful whenever a long waveform is required. Furthermore, the waveform generation time does not depend on the complexity of the underlying surrogate model. The training WFs can be computed with high accuracy, also at high computational cost, without affecting the performance of the WF generation.
\par
This fact is crucial for detection of low frequency signals, as is the case for ET. The analysis of such signals can be performed in the same time required to deal with shorter signals: it will become feasible, even with a small amount of resourches, \textit{without any loss of WF quality}.
In \cite{} (\textbf{plot in email}), it was shown that training model TEOBResumS matches accurately the numerical relativity WFs, even in the case of ET noise curve is used (see plot in the email). Since our model closely reproduces TEOBResumS, it is likely to achieve the target accuracy for the employment in the ET data analysis.
\textbf{Here I wanted to include the plot sent by Nagar. Is it in a paper? Do we include it here? Or do we just skip it??}
\par
As already noted, the fact that a parameter estimation with \texttt{mlgw} is remarkably fast opens up the opportunity for an analysis of the catalog of all the observed GW events.
By training (and the training procedure is moderately quick) \texttt{mlgw} with different surrogate models, it will be possible to compare their predictions on several observed events. This could allow to detect systematic biases or to prefer a model over another by means of Bayesian model selection (i.e. by comparing different model evidences).
A further paper will be devoted to such analysis.
\par
\textbf{Is there more to say on that?? E.g. about ROM??}\\
\par
However, our work is far from being over and several issues still require attention.
\par
First of all, the potential speed up of parameter estimation can be even higher, if we take advantage of the closed form expression of the waveform provided by our model.
Indeed, a closed form expression for the WF allows for prompt computation of the gradients with respect to the orbital parameters $ \boldsymbol{\vartheta} = (m_1,m_2, {s}_1,{s}_2) $.
Hamiltonian Montecarlo \cite{betancourt2017hamiltonianMC}~\cite{Porter2014Hamiltonian_MonteCarlo}, a variant of Markov chain Montecarlo, employs gradients of the waveform to perform an effective sampling of the posterior distibution, which is able to ``find quickly" the high density regions.
%Porter and Carré \cite{Porter2014Hamiltonian_MonteCarlo} applied Hamiltonian Montecarlo to parameter estimation. However, they only use analytical waveforms, which completely neglects the late inspiral and the merger.
%Our Machine Learning model could, in principle, extend the application of Hamiltonian Montecarlo to waveform which included also late inspiral, merger and ringdown.
It would provide a state-of-the-art accurate parameter estimation and, at the same time, it will offer a substantial speed up.
We believe that this is a promising option and it is among the natural continuations of our work.
\par
Another option, so far never explored, is to use the gradients of the WF for a fast exploration of the likelihood landscape. With any gradient based optimizer, it should be easy to jump to a \textit{local} maximum of the likelihood. Such information can be used to reliably locate a \textit{global} maximum of the likelihood. Once a global maximum is found, the sampling from the posterior distribution should be quicker to perform, yielding an improvement to the overall analysis.
\par
In our model we did not consider precessing system. We made this choice to keep the problem simple.
The expertise gained for the simple non precessing case can be applied to deal with the complicacies posed by the precessing case.
A good starting point is given in \cite{Schmidt2015Precession}. The dynamics (dependent on 6 parameters) is mapped to a simpler problem, where the precession is controlled by a single parameter. The mapping is as follows:
\begin{align*}
	(s_{1x},s_{1y}, s_{1z}) &\longmapsto (s_{P},0, s_{1z})\\
	(s_{2x},s_{2y}, s_{2z}) &\longmapsto (0, 0, s_{2z})
\end{align*}
where $s_P = s_P(q,s_{1x},s_{1y}, s_{2x},s_{2y})$ (see \cite[eq. 3]{Schmidt2015Precession}).
In the authors' word, the effective spin parameter $s_{P}$ "accurately captures the dominant precession-induced features in GW signals across the full parameter space".
The waveform dependence on the effective spin parameter $s_P$ can be fitted by a ML model in the same fashion of the other orbital parameters, thus simplyfing the regression problem.
\par
All surrogate models provides numerical solutions to approximate form of the Einstein equations. They are useful to catch the dominant physics but we expect them to show a degree of inaccuracy, especially close to coalescence.
Numerical relativity solves numerically the unapproximated Einstein equations and so far yields the best available solutions.
Clearly, NR waveforms are much slow to generate and cannot be used in parameter estimation.
Our model could be trained on the publicly available NR waveforms catalogs (see e.g. \cite{Mroue2013NRWFcatalog} and \cite{Healy2017NRWFcatalog}) and would provide the best generalization of the numerical waveform.
If the model proved to be reliable and effective, we could dispense with the surrogate models altogether and use only NR inputs for parameter estimation. This would ensure that all the relevant physics close to merger is adequately captured.
Furthermore, a training set of NR waveforms can be used to address problems where an approximation to Einstein equations (such as PN expansion) is not available.
\par
\textbf{Are you sure of it??? Probably you should say that you don't know enough on the matter and that you will have to investigate...}\\
Unfortunately, at the moment there are too few NR waveforms ($O(10^2)$) available to perform a reliable training: we need at least $O(10^3)$ waveforms. However, in the future we expect more and more waveforms to be included in the dataset, eventually allowing for a reliable training.
Furthermore, NR waveforms are too short as compared to detected signals in interferometers. Probably, some form of hybridization from PN models is required to tackle the inspiral phase.
\par
Our machine learning approach to signal generation is very flexible and it provides a general framework. We expect it to work for every source for which a number of training waveforms are available (also those for which no surrogate models are available).
Machine learning models for various range of sources can be crucial in the future, where signals from a number of different sources are expected to be detected. In that scenario, a parameter estimation must be able to detect among different source and this will require a lot of computational work. Speed up will be more pressing.












